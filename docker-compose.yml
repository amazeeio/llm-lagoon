version: '2'
services:
  llama2-api:
    build:
      context: .
      dockerfile: gpu.Dockerfile
    labels:
      lagoon.type: basic-persistent
      lagoon.persistent: /data
      lagoon.service.port: 8000
      lagoon.autogeneratedroute: true
      lagoon.gpu: true
    volumes:
      - ./app:/app:delegated
    ports:
      - "8000:8000"
